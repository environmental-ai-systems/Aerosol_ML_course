{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning for Aerosol Scientists\n",
    "## Part 1: XGBoost for UVLIF Aerosol Classification\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this notebook, you will understand:\n",
    "1. Train/test/validation splits and why they matter\n",
    "2. Model evaluation using ROC curves and other metrics\n",
    "3. Hyperparameter tuning to optimize model performance\n",
    "4. How to apply gradient boosting (XGBoost) to classify aerosol types\n",
    "\n",
    "### Background\n",
    "UVLIF mass spectrometry generates fluorescence spectra that can distinguish between different aerosol types (biological, mineral dust, organic carbon, etc.). We'll use machine learning to automate this classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install xgboost scikit-learn matplotlib seaborn pandas numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_curve, auc, roc_auc_score)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic UVLIF Data\n",
    "\n",
    "We'll create synthetic aerosol mass spectra for 4 aerosol types:\n",
    "- **Biological**: Strong fluorescence at specific wavelengths (characteristic of proteins/NAD(P)H)\n",
    "- **Mineral Dust**: Weak, broad fluorescence\n",
    "- **Organic Carbon**: Moderate fluorescence with different spectral features\n",
    "- **Polycyclic Aromatic Hydrocarbons (PAH)**: Strong fluorescence at longer wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uvlif_spectrum(aerosol_type, n_wavelengths=64, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generate synthetic UVLIF spectrum for different aerosol types.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    aerosol_type : str\n",
    "        Type of aerosol ('biological', 'mineral_dust', 'organic_carbon', 'pah')\n",
    "    n_wavelengths : int\n",
    "        Number of spectral channels (wavelength bins)\n",
    "    noise_level : float\n",
    "        Amount of random noise to add\n",
    "    \"\"\"\n",
    "    wavelengths = np.linspace(0, 1, n_wavelengths)\n",
    "    \n",
    "    if aerosol_type == 'biological':\n",
    "        # Two peaks: tryptophan-like (~280nm) and NAD(P)H-like (~340-460nm)\n",
    "        spectrum = (3.0 * np.exp(-((wavelengths - 0.3)**2) / 0.01) + \n",
    "                   4.0 * np.exp(-((wavelengths - 0.5)**2) / 0.02))\n",
    "        \n",
    "    elif aerosol_type == 'mineral_dust':\n",
    "        # Weak, broad, nearly flat response\n",
    "        spectrum = 0.5 + 0.3 * np.exp(-((wavelengths - 0.5)**2) / 0.5)\n",
    "        \n",
    "    elif aerosol_type == 'organic_carbon':\n",
    "        # Single broader peak in mid-range\n",
    "        spectrum = 2.5 * np.exp(-((wavelengths - 0.4)**2) / 0.03)\n",
    "        \n",
    "    elif aerosol_type == 'pah':\n",
    "        # Strong peak at longer wavelengths\n",
    "        spectrum = 5.0 * np.exp(-((wavelengths - 0.7)**2) / 0.02)\n",
    "    \n",
    "    # Add realistic noise\n",
    "    noise = noise_level * np.random.randn(n_wavelengths)\n",
    "    spectrum = spectrum + noise\n",
    "    \n",
    "    # Ensure non-negative (like real fluorescence data)\n",
    "    spectrum = np.maximum(spectrum, 0)\n",
    "    \n",
    "    return spectrum\n",
    "\n",
    "# Generate dataset\n",
    "np.random.seed(42)\n",
    "n_samples_per_class = 250\n",
    "aerosol_types = ['biological', 'mineral_dust', 'organic_carbon', 'pah']\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for aerosol_type in aerosol_types:\n",
    "    for _ in range(n_samples_per_class):\n",
    "        spectrum = generate_uvlif_spectrum(aerosol_type)\n",
    "        data.append(spectrum)\n",
    "        labels.append(aerosol_type)\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array(data)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Classes: {aerosol_types}\")\n",
    "print(f\"Samples per class: {n_samples_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize example spectra for each aerosol type\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, aerosol_type in enumerate(aerosol_types):\n",
    "    # Get indices for this class\n",
    "    class_indices = np.where(y == aerosol_type)[0]\n",
    "    \n",
    "    # Plot several examples\n",
    "    for i in range(5):\n",
    "        axes[idx].plot(X[class_indices[i]], alpha=0.6, linewidth=1.5)\n",
    "    \n",
    "    axes[idx].set_title(f'{aerosol_type.replace(\"_\", \" \").title()}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Wavelength Channel', fontsize=10)\n",
    "    axes[idx].set_ylabel('Fluorescence Intensity', fontsize=10)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('example_spectra.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Note the characteristic spectral signatures:\")\n",
    "print(\"- Biological: Two distinct peaks (proteins and NAD(P)H)\")\n",
    "print(\"- Mineral Dust: Weak, broad response\")\n",
    "print(\"- Organic Carbon: Single moderate peak\")\n",
    "print(\"- PAH: Strong peak at longer wavelengths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train/Test/Validation Split\n",
    "\n",
    "### Why do we need multiple data splits?\n",
    "\n",
    "1. **Training Set (60%)**: Used to train the model (learn patterns)\n",
    "2. **Validation Set (20%)**: Used to tune hyperparameters and make decisions during model development\n",
    "3. **Test Set (20%)**: Held out completely until the end - gives unbiased estimate of real-world performance\n",
    "\n",
    "**Critical concept**: The test set must NEVER be used during model development. It's your \"honest estimate\" of how the model will perform on new, unseen aerosol samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: separate out test set (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: divide remaining data into train (75% of 80% = 60%) and validation (25% of 80% = 20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Data splits:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(\"\\n✓ Test set is locked away - we won't touch it until final evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling - important for many ML algorithms\n",
    "# Fit scaler on training data only!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"✓ Data scaled and labels encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train a Baseline XGBoost Model\n",
    "\n",
    "**What is XGBoost?**\n",
    "- Gradient Boosting algorithm: builds an ensemble of decision trees sequentially\n",
    "- Each new tree corrects errors made by previous trees\n",
    "- Very effective for tabular/structured data (like spectra)\n",
    "- Popular in competitions and real-world applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model with default parameters\n",
    "baseline_model = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'  # multiclass log loss\n",
    ")\n",
    "\n",
    "baseline_model.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_predictions = baseline_model.predict(X_val_scaled)\n",
    "val_accuracy = (val_predictions == y_val_encoded).mean()\n",
    "\n",
    "print(f\"Baseline Model Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "print(\"\\nClassification Report (Validation Set):\")\n",
    "print(classification_report(y_val_encoded, val_predictions, \n",
    "                          target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val_encoded, val_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix - Baseline Model', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_baseline.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHow to read this: Diagonal = correct predictions, Off-diagonal = errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: ROC Curves and AUC\n",
    "\n",
    "**Receiver Operating Characteristic (ROC) curves** show the trade-off between:\n",
    "- **True Positive Rate (Sensitivity)**: Correctly identifying aerosol type\n",
    "- **False Positive Rate**: Incorrectly classifying other types as this type\n",
    "\n",
    "**Area Under Curve (AUC)**:\n",
    "- AUC = 1.0: Perfect classifier\n",
    "- AUC = 0.5: Random guessing\n",
    "- AUC > 0.9: Excellent performance\n",
    "\n",
    "For multi-class problems, we compute one ROC curve per class (one-vs-rest approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions\n",
    "y_val_proba = baseline_model.predict_proba(X_val_scaled)\n",
    "\n",
    "# Binarize labels for ROC curve (one-vs-rest)\n",
    "y_val_bin = label_binarize(y_val_encoded, classes=range(len(aerosol_types)))\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(aerosol_types)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "\n",
    "for i, (color, aerosol_type) in enumerate(zip(colors, aerosol_types)):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'{aerosol_type.replace(\"_\", \" \").title()} (AUC = {roc_auc[i]:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curves - Baseline XGBoost Model', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves_baseline.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Curves closer to top-left corner = better performance\")\n",
    "print(\"- AUC closer to 1.0 = better discrimination ability\")\n",
    "print(f\"- Mean AUC across classes: {np.mean(list(roc_auc.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Hyperparameter Tuning\n",
    "\n",
    "**Hyperparameters** are settings that control the learning process (not learned from data).\n",
    "\n",
    "Key XGBoost hyperparameters:\n",
    "- **n_estimators**: Number of trees (more trees = more complex model)\n",
    "- **max_depth**: Maximum depth of each tree (deeper = more complex)\n",
    "- **learning_rate**: How much each tree contributes (smaller = more conservative)\n",
    "- **subsample**: Fraction of samples used for each tree (prevents overfitting)\n",
    "\n",
    "We use **Grid Search** with **Cross-Validation** to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "print(f\"Testing {np.prod([len(v) for v in param_grid.values()])} parameter combinations...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Create XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Baseline Validation Score: {val_accuracy:.4f}\")\n",
    "print(f\"\\nImprovement: {(grid_search.best_score_ - val_accuracy)*100:.2f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_predictions_tuned = best_model.predict(X_val_scaled)\n",
    "val_accuracy_tuned = (val_predictions_tuned == y_val_encoded).mean()\n",
    "\n",
    "print(\"\\nTuned Model Performance:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Validation Accuracy: {val_accuracy_tuned:.4f} ({val_accuracy_tuned*100:.2f}%)\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_encoded, val_predictions_tuned,\n",
    "                          target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare ROC curves: Baseline vs Tuned\n",
    "y_val_proba_tuned = best_model.predict_proba(X_val_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot for baseline\n",
    "for i, (color, aerosol_type) in enumerate(zip(colors, aerosol_types)):\n",
    "    fpr_base, tpr_base, _ = roc_curve(y_val_bin[:, i], y_val_proba[:, i])\n",
    "    roc_auc_base = auc(fpr_base, tpr_base)\n",
    "    axes[0].plot(fpr_base, tpr_base, color=color, lw=2,\n",
    "                label=f'{aerosol_type.replace(\"_\", \" \").title()} (AUC = {roc_auc_base:.3f})')\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "axes[0].set_xlabel('False Positive Rate', fontsize=11)\n",
    "axes[0].set_ylabel('True Positive Rate', fontsize=11)\n",
    "axes[0].set_title('Baseline Model', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(loc=\"lower right\", fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot for tuned model\n",
    "for i, (color, aerosol_type) in enumerate(zip(colors, aerosol_types)):\n",
    "    fpr_tuned, tpr_tuned, _ = roc_curve(y_val_bin[:, i], y_val_proba_tuned[:, i])\n",
    "    roc_auc_tuned = auc(fpr_tuned, tpr_tuned)\n",
    "    axes[1].plot(fpr_tuned, tpr_tuned, color=color, lw=2,\n",
    "                label=f'{aerosol_type.replace(\"_\", \" \").title()} (AUC = {roc_auc_tuned:.3f})')\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=11)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=11)\n",
    "axes[1].set_title('Tuned Model', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\", fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Final Evaluation on Test Set\n",
    "\n",
    "**NOW** we can use our held-out test set for final evaluation. This gives us an honest estimate of real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "test_predictions = best_model.predict(X_test_scaled)\n",
    "test_accuracy = (test_predictions == y_test_encoded).mean()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTest Set Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, test_predictions,\n",
    "                          target_names=label_encoder.classes_))\n",
    "\n",
    "# Test set confusion matrix\n",
    "cm_test = confusion_matrix(y_test_encoded, test_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix - Final Test Set', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_test.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Feature Importance\n",
    "\n",
    "XGBoost can tell us which wavelength channels are most important for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = best_model.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(range(len(feature_importance)), feature_importance, color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Wavelength Channel', fontsize=12)\n",
    "plt.ylabel('Importance Score', fontsize=12)\n",
    "plt.title('Feature Importance - Which Wavelengths Matter Most?', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Show top 10 most important channels\n",
    "top_features = np.argsort(feature_importance)[-10:][::-1]\n",
    "print(\"\\nTop 10 Most Important Wavelength Channels:\")\n",
    "for i, idx in enumerate(top_features, 1):\n",
    "    print(f\"{i}. Channel {idx}: importance = {feature_importance[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Data Splitting**\n",
    "   - Training set: Learn patterns\n",
    "   - Validation set: Tune hyperparameters\n",
    "   - Test set: Final honest evaluation\n",
    "\n",
    "2. **Model Evaluation**\n",
    "   - Accuracy: Overall correct predictions\n",
    "   - Confusion Matrix: Where errors occur\n",
    "   - ROC/AUC: Trade-off between sensitivity and specificity\n",
    "   - Precision/Recall: Class-specific performance\n",
    "\n",
    "3. **Hyperparameter Tuning**\n",
    "   - Grid search explores parameter combinations\n",
    "   - Cross-validation prevents overfitting\n",
    "   - Can significantly improve performance\n",
    "\n",
    "4. **XGBoost Strengths**\n",
    "   - Excellent for structured/tabular data\n",
    "   - Handles complex patterns\n",
    "   - Provides feature importance\n",
    "\n",
    "### Next Steps:\n",
    "In the next notebook, we'll use deep neural networks (DNNs) to tackle the same problem and compare approaches!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model for potential future use\n",
    "import pickle\n",
    "\n",
    "with open('best_xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': best_model,\n",
    "        'scaler': scaler,\n",
    "        'label_encoder': label_encoder\n",
    "    }, f)\n",
    "\n",
    "print(\"✓ Model saved to 'best_xgboost_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
